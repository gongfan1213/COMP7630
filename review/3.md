以下是针对考试复习整理的 **Netshell（网络智能/Web Intelligence）核心内容详细概括**：

---

### **一、基础概念**
1. **定义**  
   - **Web Intelligence (WI)** = 人工智能（AI） + 网络技术（Web）  
   - 目标：通过智能算法处理网络数据（内容、结构、用户行为）  

2. **三大研究领域**  
   - **内容挖掘**（文本/多媒体信息提取）  
   - **结构分析**（超链接/社交网络关系）  
   - **使用挖掘**（用户点击流/行为模式）  

---

### **二、关键技术模块**
#### **1. 网络内容挖掘（Web Content Mining）**
- **任务类型**  
  - **分类**（Classification）：网页/文本标签预测（如垃圾邮件检测）  
    - 算法：SVM、随机森林、神经网络  
  - **聚类**（Clustering）：无监督分组（如新闻话题聚合）  
    - 算法：K-means、DBSCAN  
  - **信息检索**（Information Retrieval）：搜索引擎排名（如PageRank）  

- **数据预处理**  
  - HTML解析：`BeautifulSoup`提取结构化数据  
  - 文本向量化：TF-IDF、Word2Vec  

#### **2. 网络结构分析（Web Structure Analysis）**
- **核心算法**  
  - **PageRank**：基于超链接的页面重要性排序  
  - **社区发现**：识别社交网络中的紧密群体（如LinkedIn圈子）  

- **应用场景**  
  - 虚假新闻检测（通过链接来源权威性分析）  
  - 推荐系统（用户-商品二部图分析）  

#### **3. 网络使用挖掘（Web Usage Mining）**
- **数据类型**  
  - 点击流（Clickstream）、会话日志（Session Logs）  

- **典型应用**  
  - **协同过滤推荐**（"用户A喜欢的，用户B也可能喜欢"）  
  - **用户行为预测**（如购物车弃单率分析）  

---

### **三、工具与开发环境**
#### **1. Python技术栈**
- **必备库**  
  ```python
  # 数据处理
  import numpy as np
  import pandas as pd
  
  # 机器学习
  from sklearn.ensemble import RandomForestClassifier
  from sklearn.cluster import KMeans
  
  # 网络爬取
  from bs4 import BeautifulSoup
  ```

- **环境配置**  
  ```bash
  conda create -n wi python=3.11  # 创建隔离环境
  conda install scikit-learn pandas  # 核心工具
  ```

#### **2. 数据获取方法**
- **静态网页**：Requests + BeautifulSoup  
- **动态内容**：Selenium自动化  
- **API交互**：JSON/XML解析（如Twitter API）  

---

### **四、重点算法详解**
#### **1. PageRank算法**
- **核心公式**  
  \[
  PR(A) = (1-d) + d \sum_{i=1}^{n} \frac{PR(T_i)}{C(T_i)}
  \]
  - \(d\)：阻尼系数（通常0.85）  
  - \(T_i\)：链接到A的页面  
  - \(C(T_i)\)：\(T_i\)的出链总数  

- **考试要点**  
  - 解释"投票机制"（入链越多越重要）  
  - 说明阻尼系数的作用（避免排名泄漏）  

#### **2. Apriori算法（关联规则）**
- **关键步骤**  
  1. 找出频繁项集（支持度≥阈值）  
  2. 生成关联规则（置信度≥阈值）  

- **示例**  
  - 超市购物篮分析：{啤酒} → {尿布}（支持度5%，置信度70%）  

---

### **五、典型考试题型**
1. **简答题**  
   - Q：比较Web挖掘与传统数据挖掘的差异？  
   - A：  
     - 数据来源：Web数据非结构化（HTML/文本）、高噪声  
     - 技术重点：需额外处理爬取、清洗、超链接分析  

2. **计算题**  
   - 给定超链接图，计算2轮PageRank值（需掌握手动迭代方法）  

3. **代码题**  
   - 使用Scikit-learn实现文本分类（需熟悉`TfidfVectorizer` + `RandomForestClassifier`流程）  

---

### **六、易错点提醒**
1. **环境配置**  
   - 混淆`conda install`与`pip install` → 优先用conda避免依赖冲突  
2. **算法应用**  
   - PageRank仅适用于有向图（社交网络需转为有向图再计算）  
3. **数据伦理**  
   - 网络爬取需遵守`robots.txt`协议（考试可能涉及法律考点）  

---

**记忆口诀**：  
"内容分类聚类，结构链接分析，使用行为预测，工具Python当先"  

（建议结合课件中的代码示例和评估标准中的评分表进行针对性练习）
