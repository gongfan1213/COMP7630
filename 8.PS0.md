以下是《08_evolutionary2.pdf》文档的全文翻译，采用一句英文对应一句中文的形式：

---

**===== Page 1 [text layer] =====**  
COMP7630 – Web Intelligence and its Applications  
COMP7630 – 网络智能及其应用  

Evolutionary Algorithms (for continuous optimization)  
进化算法（用于连续优化）  

Valentino Santucci  
瓦伦蒂诺·桑图奇  

(valentino.santucci@unistrapg.it)  
(valentino.santucci@unistrapg.it)  

---

**===== Page 2 =====**  
# Outline  
# 大纲  

- Differential Evolution  
- 差分进化  

- Particle Swarm Optimization  
- 粒子群优化  

- Nevergrad Python library  
- Nevergrad Python库  

---

**===== Page 3 =====**  
# Differential Evolution (DE)  
# 差分进化（DE）  

- DE is one of the best optimizers for continuous problems  
- DE是连续优化问题的最佳优化器之一  

- Solutions are represented as vectors of real numbers  
- 解表示为实数向量  

- 3 genetic operators: differential mutation, crossover, selection  
- 三种遗传操作符：差分变异、交叉、选择  

- DE key component is the differential mutation which allows to automatically adjust the balance between exploitation and exploration in the course of the evolution  
- DE的关键组件是差分变异，它能在进化过程中自动调整利用与探索的平衡  

- (Hyper-)Parameters:  
- （超）参数：  

  - \( N = \) size of the population  
  - \( N = \) 群体大小  

  - \( F = \) scale factor >0, but usually in [0,1]  
  - \( F = \) 比例因子 >0，但通常在[0,1]范围内  

  - \( CR = \) crossover probability in [0,1]  
  - \( CR = \) 交叉概率，范围为[0,1]  

---

**===== Page 4 [text layer] =====**  
Workflow of DE  
DE的工作流程  

Population at generation t  
第t代群体  

Differential Mutation  
差分变异  

Mutants Population  
变异群体  

Crossover  
交叉  

1-to-1 Selection  
一对一选择  

Population at generation t+1  
第t+1代群体  

Trials Population  
试验群体  

\( v_i= x_{r0} + F(x_{r1} -x_{r2}) \)  
\( v_i= x_{r0} + F(x_{r1} -x_{r2}) \)  

---

**===== Page 5 =====**  
# Pseudo-code of DE  
# DE的伪代码  

1. Randomly initialize a population of \( N \) solutions \(\{x_1, ..., x_N\}\)  
1. 随机初始化包含N个解的群体 \(\{x_1, ..., x_N\}\)  

2. While ( termination criterion is not verified )  
2. 当（终止条件未满足时）  

a. For \( i = 1, ..., N \)  
a. 对于 \( i = 1, ..., N \)  

   * Generate a mutant \( v_i = x_{r0} + F \cdot (x_{r1} - x_{r2}) \)  
   * 生成变异体 \( v_i = x_{r0} + F \cdot (x_{r1} - x_{r2}) \)  

b. For \( i = 1, ..., N \)  
b. 对于 \( i = 1, ..., N \)  

   * Generate a trial \( u_i = crossover(x_i, v_i) \)  
   * 生成试验解 \( u_i = crossover(x_i, v_i) \)  

   * The previously seen uniform crossover may also work with real vectors  
   * 之前提到的均匀交叉也可用于实数向量  

c. For \( i = 1, ..., N \)  
c. 对于 \( i = 1, ..., N \)  

   * Evaluate \( f(u_i) \)  
   * 评估 \( f(u_i) \)  

   * Replace \( x_i \) with \( u_i \) if it is better  
   * 如果 \( u_i \) 更优，则用其替换 \( x_i \)  

---  

**Differential Mutation**  
**差分变异**  

| Crossover | Differentiation |  
| 交叉 | 差分 |  

| Selection    |    |  
| 选择    |    |  

---

**===== Page 6 =====**  
# Differential Evolution  
# 差分进化  

- \( x_1 \)  
- \( x_1 \)  

- \( u_{i,g} \)  
- \( u_{i,g} \)  

- \( v_{i,g} = u_{i,g} \)  
- \( v_{i,g} = u_{i,g} \)  

- \( x_{r0,g} \)  
- \( x_{r0,g} \)  

- \( F(x_{r1,g} - x_{r2,g}) \)  
- \( F(x_{r1,g} - x_{r2,g}) \)  

- \( x_{r2,g} \)  
- \( x_{r2,g} \)  

- \( x_0 \)  
- \( x_0 \)  

---

**===== Page 7 =====**  
# DE Dynamics (population vs differences)  
# DE动态（群体与差异）  

## Peaks function  
## Peaks函数  

- Difference vector distribution  
- 差异向量分布  

- Difference vector distribution  
- 差异向量分布  

---  

### Peaks function  
### Peaks函数  

- Difference vector distribution  
- 差异向量分布  

- Difference vector distribution  
- 差异向量分布  

---  

### Peaks function  
### Peaks函数  

- Difference vector distribution  
- 差异向量分布  

- Difference vector distribution  
- 差异向量分布  

---

**===== Page 8 =====**  
# Outline  
# 大纲  

- Differential Evolution  
- 差分进化  

- Particle Swarm Optimization  
- 粒子群优化  

- Nevergrad Python library  
- Nevergrad Python库  

---

**===== Page 9 [text layer] =====**  
From Competition to Cooperation: Swarm intelligence  
从竞争到合作：群体智能  

• Swarm intelligence deals with systems composed of many individuals that coordinate using decentralized control and self-organization  
• 群体智能研究由许多个体组成的系统，这些个体通过分散控制和自组织进行协调  

• In particular, it focuses on the collective behaviors that emerges from the local interactions of the individuals with each other and with their environment and without the presence of a coordinator.  
• 特别是，它关注个体之间以及个体与环境之间的局部相互作用所涌现的集体行为，且无需协调者的参与。  

• Examples:  
• 示例：  

• Schools of fish  
• 鱼群  

• Flocks of birds  
• 鸟群  

• Colonies of ants and termites  
• 蚂蚁和白蚁的群体  

• …  
• …  

---

**===== Page 10 =====**  
# Particle Swarm optimization  
# 粒子群优化  

- PSO maintains a population of particles connected in a neighborhood topology.  
- PSO维护一个在邻域拓扑中连接的粒子群体。  

- Each particle is composed by:  
- 每个粒子包含：  

  - \( x_i \in \mathbb{R}^n \) => current position  
  - \( x_i \in \mathbb{R}^n \) => 当前位置  

  - \( v_i \in \mathbb{R}^n \) => velocity  
  - \( v_i \in \mathbb{R}^n \) => 速度  

  - \( p_i \in \mathbb{R}^n \) => personal best position  
  - \( p_i \in \mathbb{R}^n \) => 个体历史最佳位置  

  - \( g_i \in \mathbb{R}^n \) => neighborhood best position (eg: global best)  
  - \( g_i \in \mathbb{R}^n \) => 邻域最佳位置（例如：全局最佳）  

- Particles are arranged in a neighborhood (es: global or ring)  
- 粒子按邻域排列（例如：全局或环形）  

---

**===== Page 11 =====**  
# Particle Swarm optimization  
# 粒子群优化  

- Randomly initialize particles  
- 随机初始化粒子  

- While (termination criterion not met)  
- 当（终止条件未满足时）  

  - For each particle:  
  - 对于每个粒子：  

    - Update particle velocity  
    - 更新粒子速度  

    - Update particle position  
    - 更新粒子位置  

    - Evaluate particle position  
    - 评估粒子位置  

    - Update particle personal best  
    - 更新粒子个体历史最佳  

- For each particle:  
- 对于每个粒子：  

    - Update particle neighborhood best  
    - 更新粒子邻域最佳  

---

**===== Page 12 [text layer] =====**  
Workflow of PSO  
PSO的工作流程  

---

**===== Page 13 =====**  
# Particle swarm optimization  
# 粒子群优化  

- Position and velocity update:  
- 位置和速度更新：  

  - \( v_i \leftarrow wv_i + c_1r_1(p_i - x_i) + c_2r_2(g_i - x_i) \) => velocity update rule  
  - \( v_i \leftarrow wv_i + c_1r_1(p_i - x_i) + c_2r_2(g_i - x_i) \) => 速度更新规则  

  - \( x_i \leftarrow x_i + v_i \) => position update rule  
  - \( x_i \leftarrow x_i + v_i \) => 位置更新规则  

- PSO parameters:  
- PSO参数：  

  - \( w \in \mathbb{R}^+ \) => inertial coefficient  
  - \( w \in \mathbb{R}^+ \) => 惯性系数  

  - \( c_1 \in \mathbb{R}^+ \) => cognitive coefficient  
  - \( c_1 \in \mathbb{R}^+ \) => 认知系数  

  - \( c_2 \in \mathbb{R}^+ \) => social coefficient  
  - \( c_2 \in \mathbb{R}^+ \) => 社会系数  

---

**===== Page 14 =====**  
Movement of a PSO particle  
PSO粒子的运动  

\( x_i^{t+1} \)  
\( x_i^{t+1} \)  

Particle move  
粒子移动  

Social move  
社会移动  

Cognitive move  
认知移动  

Inertial move  
惯性移动  

\( x_i^t \)  
\( x_i^t \)  

---

**===== Page 15 =====**  
# PSO Dynamics  
# PSO动态  

- \( y \)  
- \( y \)  

- search space  
- 搜索空间  

- \( x \)  
- \( x \)  

- fitness  
- 适应度  

- max  
- 最大  

- min  
- 最小  

---

**===== Page 16 =====**  
# PSO Dynamics  
# PSO动态  

- y  
- y  

- x  
- x  

- max  
- 最大  

- min  
- 最小  

- fitness  
- 适应度  

search space  
搜索空间  

---

**===== Page 17 =====**  
PSO Dynamics  
PSO动态  

y  
y  

x  
x  

search space  
搜索空间  

---

**===== Page 18 =====**  
PSO Dynamics  
PSO动态  

y  
y  

x  
x  

search space  
搜索空间  

---

**===== Page 19 =====**  
PSO Dynamics  
PSO动态  

y  
y  

x  
x  

search space  
搜索空间  

---

**===== Page 20 =====**  
PSO dynamics  
PSO动态  

y  
y  

search space  
搜索空间  

x  
x  

fitness  
适应度  

max  
最大  

min  
最小  

search space  
搜索空间  

---

**===== Page 21 =====**  
PSO dynamics  
PSO动态  

y  
y  

search space  
搜索空间  

x  
x  

fitness  
适应度  

max  
最大  

min  
最小  

search space  
搜索空间  

---

**===== Page 22 =====**  
PSO Dynamics  
PSO动态  

y  
y  

x  
x  

search space  
搜索空间  

---

**===== Page 23 =====**  
# Outline  
# 大纲  

- Differential Evolution  
- 差分进化  

- Particle Swarm Optimization  
- 粒子群优化  

- Nevergrad Python library  
- Nevergrad Python库  

---

**===== Page 24 =====**  
# Nevergrad  
# Nevergrad  

- Nevergrad is a Python library containing a collection of evolutionary algorithms  
- Nevergrad是一个包含多种进化算法的Python库  

- Install it with: pip install nevergrad  
- 安装命令：pip install nevergrad  

---

**===== Page 25 =====**  
# DE with Nevergrad  
# 使用Nevergrad实现DE  

**In [43]: import nevergrad as ng**  
**In [43]: 导入nevergrad库，命名为ng**  

**In [44]: import numpy as np**  
**In [44]: 导入numpy库，命名为np**  

**In [45]: *define a simple objective function, just as an example***  
**In [45]: *定义一个简单的目标函数，仅作示例***  

**In [46]: def sphere_objective_function(x): ______ and simple benchmark in the field**  
**In [46]: def sphere_objective_function(x): ______ 该领域的简单基准测试**  
    ...: return np.sum(x**2)  
    ...: 返回np.sum(x**2)  

**In [47]: *optimize the objective function using Differential Evolution***  
**In [47]: *使用差分进化优化目标函数***  

**In [48]: optimizer = ng.optimizers.DEC parameterization=30, budget=10.000()**  
**In [48]: optimizer = ng.optimizers.DEC parameterization=30, budget=10.000()**  

**In [49]: result = optimizer.minimize( sphere_objective_function )**  
**In [49]: result = optimizer.minimize( sphere_objective_function )**  

**In [50]: *print the objective value of the optimum and the vector values of the optimum***  
**In [50]: *打印最优解的目标值和向量值***  

**In [51]: result.loss**  
**In [51]: result.loss**  

**Out[51]: 8.2698661999997661**  
**Out[51]: 8.2698661999997661**  

**In [52]: result.value**  
**In[52]: result.value**  

**Out[52]: ______**  
**Out[52]: ______**  

**array([ 8.79658218e-02,  3.85643137e-03, -8.88580577e-04, -2.647080478e-01, 7.76468117e-02,  8.92546638e-02, -9.55805127e-02, -1.142890624e-01, 1.97019443e-02, -9.15763578e-02,  1.12404646e-01, -1.48993356e-05, 4.79471482e-02, -8.49231815e-02,  1.39927968e-01,  2.38893946e-02, 1.177361718e-01,  5.66886932e-02, -4.68958181e-02, -4.66136222e-03, -1.14261219e-01,  1.82622579e-03, -1.66695317e-01, -6.37998272e-02, -1.21875581e-02, -5.11934821e-02, -6.92388772e-02, -9.57985118e-02, -9.84461997e-04, -4.75669532e-03])**  
**数组([ 8.79658218e-02,  3.85643137e-03, -8.88580577e-04, -2.647080478e-01, 7.76468117e-02,  8.92546638e-02, -9.55805127e-02, -1.142890624e-01, 1.97019443e-02, -9.15763578e-02,  1.12404646e-01, -1.48993356e-05, 4.79471482e-02, -8.49231815e-02,  1.39927968e-01,  2.38893946e-02, 1.177361718e-01,  5.66886932e-02, -4.68958181e-02, -4.66136222e-03, -1.14261219e-01,  1.82622579e-03, -1.66695317e-01, -6.37998272e-02, -1.21875581e-02, -5.11934821e-02, -6.92388772e-02, -9.57985118e-02, -9.84461997e-04, -4.75669532e-03])**  

---  

The sphere function is a common and simple benchmark in the field  
Sphere函数是该领域常见且简单的基准测试  

Parametrization is the dimensionality of solutions' vectors, while budget is the number of evaluations allowed  
Parametrization是解向量的维度，budget是允许的评估次数  

---  

The loss is the term used for the best objective value in Nevergrad  
loss是Nevergrad中用于表示最佳目标值的术语  

This is the best vector found  
这是找到的最佳向量  

---

**===== Page 26 =====**  
# PSO with Nevergrad  
# 使用Nevergrad实现PSO  

In [54]: import nevergrad as ng  
In [54]: 导入nevergrad库，命名为ng  

In [55]: import numpy as np  
In [55]: 导入numpy库，命名为np  

In [56]: #define a stalpe objective function, just as an example  
In [56]: #定义一个简单的目标函数，仅作示例  

In [57]: def sphere_objective_function(x): ...: return np.sum(x**2) ...  
In [57]: def sphere_objective_function(x): ...: 返回np.sum(x**2) ...  

In [58]: #optimize the objective function using Particle Swarm Optimization  
In [58]: #使用粒子群优化优化目标函数  

In [59]: optimizer = ng.optimizers.RealSpacePSOC( parametrization=30, budget=10_000 )  
In [59]: optimizer = ng.optimizers.RealSpacePSOC( parametrization=30, budget=10_000 )  

In [60]: result = optimizer.minimized sphere_objective_function )  
In [60]: result = optimizer.minimized sphere_objective_function )  

In [61]: #print the objective value of the optimum and the vector values of the optimum  
In [61]: #打印最优解的目标值和向量值  

In [62]: result.loss  
In [62]: result.loss  

Out[62]: 1.5728934539318212e-07  
Out[62]: 1.5728934539318212e-07  

In [63]: result.value  
In [63]: result.value  

Out[63]: array([-5.99897887e-07, -6.97273841e-05, -8.75388255e-05, -4.40332547e-05, 5.73672219e-05, -1.54354209e-04, -6.99193879e-05, -8.19045949e-06, 8.88336889e-05, -1.66535026e-04, 3.50851545e-05, 2.08195656e-05, -9.71832794e-05, -4.15782172e-05, -3.95327177e-05, -3.89925895e-05, -3.85561566e-05, 1.08404165e-04, -1.21904268e-04, 3.72599115e-05, -1.48946181e-05, -5.02274742e-05, 1.54592393e-05, -7.58946402e-05, -7.79804819e-05, -4.51165661e-05, 5.51566964e-05, 9.87827627e-05, -3.89297696e-05, 5.27985658e-05])  
Out[63]: 数组([-5.99897887e-07, -6.97273841e-05, -8.75388255e-05, -4.40332547e-05, 5.73672219e-05, -1.54354209e-04, -6.99193879e-05, -8.19045949e-06, 8.88336889e-05, -1.66535026e-04, 3.50851545e-05, 2.08195656e-05, -9.71832794e-05, -4.15782172e-05, -3.95327177e-05, -3.89925895e-05, -3.85561566e-05, 1.08404165e-04, -1.21904268e-04, 3.72599115e-05, -1.48946181e-05, -5.02274742e-05, 1.54592393e-05, -7.58946402e-05, -7.79804819e-05, -4.51165661e-05, 5.51566964e-05, 9.87827627e-05, -3.89297696e-05, 5.27985658e-05])  

---

**===== Page 27 =====**  
# References  
# 参考文献  

- Original article about DE:  
- 关于DE的原始文章：  

  [https://www.cp.eng.chula.ac.th/~prabhas//teaching/ec/ec2012/storn_price_de.pdf](http://www.cp.eng.chula.ac.th/~prabhas//teaching/ec/ec2012/storn_price_de.pdf)  

- Original article about PSO:  
- 关于PSO的原始文章：  

  [http://staff.washington.edu/paymana/swarm/kennedy95-ijcnn.pdf](http://staff.washington.edu/paymana/swarm/kennedy95-ijcnn.pdf)  

- Nevergrad Documentation:  
- Nevergrad文档：  

  [https://facebookresearch.github.io/nevergrad/](http://facebookresearch.github.io/nevergrad/)  

--- 

（翻译结束）
