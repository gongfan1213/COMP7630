===== Page 1 =====  
COMP7630 - Web Intelligence and its Applications  
COMP7630 - ç½‘ç»œæ™ºèƒ½åŠå…¶åº”ç”¨  

Association Rules  
å…³è”è§„åˆ™  

Valentino Santucci  
ç“¦ä¼¦è’‚è¯ºÂ·æ¡‘å›¾å¥‡  

(valentino.santucci@unistrapg.it)  
ï¼ˆç”µå­é‚®ä»¶ï¼švalentino.santucci@unistrapg.itï¼‰  

===== Page 2 =====  
# Mining Association Rules  
# æŒ–æ˜å…³è”è§„åˆ™  

- Mining association rules allows to discover regularities in data  
- æŒ–æ˜å…³è”è§„åˆ™å¯ä»¥å‘ç°æ•°æ®ä¸­çš„è§„å¾‹æ€§  

- Objective: to find all co-occurrence relationships among data items  
- ç›®æ ‡ï¼šå‘ç°æ•°æ®é¡¹ä¹‹é—´çš„æ‰€æœ‰å…±ç°å…³ç³»  

- Classic application: market basket data analysis, which aims to discover how items purchased by customers in a supermarket (or a store) are associated  
- ç»å…¸åº”ç”¨ï¼šè´­ç‰©ç¯®æ•°æ®åˆ†æï¼Œæ—¨åœ¨å‘ç°é¡¾å®¢åœ¨è¶…å¸‚ï¼ˆæˆ–å•†åº—ï¼‰ä¸­è´­ä¹°çš„å•†å“ä¹‹é—´çš„å…³è”  

===== Page 3 =====  
# Example Association Rule  
# å…³è”è§„åˆ™ç¤ºä¾‹  

Cheese â†’ Beer  
å¥¶é…ª â†’ å•¤é…’  

\[ \text{[support = 10%, confidence = 80%]} \]  
\[ \text{[æ”¯æŒåº¦ = 10%ï¼Œç½®ä¿¡åº¦ = 80%]} \]  

- (Support) 10% of the customers buy Cheese and Beer together  
- ï¼ˆæ”¯æŒåº¦ï¼‰10%çš„é¡¾å®¢åŒæ—¶è´­ä¹°å¥¶é…ªå’Œå•¤é…’  

- (Confidence) Customers who buy Cheese also buy Beer 80% of the times  
- ï¼ˆç½®ä¿¡åº¦ï¼‰è´­ä¹°å¥¶é…ªçš„é¡¾å®¢ä¸­æœ‰80%ä¹Ÿä¼šè´­ä¹°å•¤é…’  

- Support and Confidence are two measures of rule strength  
- æ”¯æŒåº¦å’Œç½®ä¿¡åº¦æ˜¯è¡¡é‡è§„åˆ™å¼ºåº¦çš„ä¸¤ä¸ªæŒ‡æ ‡  

===== Page 4 =====  
Possible applications in the web  
ç½‘ç»œä¸­çš„å¯èƒ½åº”ç”¨  

Purchases patterns in e-commerce websites  
ç”µå­å•†åŠ¡ç½‘ç«™ä¸­çš„è´­ä¹°æ¨¡å¼  

Word co-occurrence relationships  
è¯è¯­å…±ç°å…³ç³»  

Hashtag suggestion in social networks  
ç¤¾äº¤åª’ä½“ä¸­çš„è¯é¢˜æ ‡ç­¾å»ºè®®  

Web usage patterns  
ç½‘ç»œä½¿ç”¨æ¨¡å¼  

===== Page 5 =====  
# Definitions  
# å®šä¹‰  

- \( I = \{t_1, t_2, ..., t_m\} \) is the universe set of items  
- \( I = \{t_1, t_2, ..., t_m\} \) æ˜¯æ‰€æœ‰ç‰©å“çš„å…¨é›†  

- \( T = \{t_1, t_2, ..., t_n\} \) is the set (or database) of transactions  
- \( T = \{t_1, t_2, ..., t_n\} \) æ˜¯äº‹åŠ¡çš„é›†åˆï¼ˆæˆ–æ•°æ®åº“ï¼‰  

- \( t_i \subseteq I \), i.e., each transaction is a subset of items  
- \( t_i \subseteq I \)ï¼Œå³æ¯ä¸ªäº‹åŠ¡æ˜¯ç‰©å“çš„ä¸€ä¸ªå­é›†  

- An association rule is an implication of the form  
- å…³è”è§„åˆ™æ˜¯ä¸€ç§å½¢å¼çš„è•´å«å…³ç³»  

  \[ X \to Y, \text{ where: } X \subset I, Y \subset I, X \cap Y = \emptyset \]  
  \[ X \to Y, \text{ å…¶ä¸­: } X \subset I, Y \subset I, X \cap Y = \emptyset \]  

- \( X \) and \( Y \) are called itemsets  
- \( X \) å’Œ \( Y \) è¢«ç§°ä¸ºé¡¹é›†  

===== Page 6 =====  
# An example  
# ç¤ºä¾‹  

**Example 1:** We want to analyze how the items sold in a supermarket are related to one another. \( I \) is the set of all items sold in the supermarket. A transaction is simply a set of items purchased in a basket by a customer. For example, a transaction may be:  
**ç¤ºä¾‹1ï¼š** æˆ‘ä»¬æƒ³åˆ†æè¶…å¸‚ä¸­é”€å”®çš„å•†å“ä¹‹é—´çš„å…³ç³»ã€‚\( I \) æ˜¯è¶…å¸‚ä¸­é”€å”®çš„æ‰€æœ‰å•†å“çš„é›†åˆã€‚ä¸€ä¸ªäº‹åŠ¡å°±æ˜¯é¡¾å®¢åœ¨è´­ç‰©ç¯®ä¸­è´­ä¹°çš„ä¸€ç»„å•†å“ã€‚ä¾‹å¦‚ï¼Œä¸€ä¸ªäº‹åŠ¡å¯èƒ½æ˜¯ï¼š  

\[\{ \text{Beef, Chicken, Cheese} \},\]  
\[\{ \text{ç‰›è‚‰, é¸¡è‚‰, å¥¶é…ª} \},\]  

which means that a customer purchased three items in a basket, Beef, Chicken, and Cheese. An association rule may be:  
è¿™è¡¨ç¤ºé¡¾å®¢åœ¨è´­ç‰©ç¯®ä¸­è´­ä¹°äº†ä¸‰ç§å•†å“ï¼šç‰›è‚‰ã€é¸¡è‚‰å’Œå¥¶é…ªã€‚ä¸€ä¸ªå…³è”è§„åˆ™å¯èƒ½æ˜¯ï¼š  

\[\text{Beef, Chicken} \rightarrow \text{Cheese},\]  
\[\text{ç‰›è‚‰, é¸¡è‚‰} \rightarrow \text{å¥¶é…ª},\]  

where \(\{ \text{Beef, Chicken} \}\) is \( X \) and \(\{ \text{Cheese} \}\) is \( Y \). For simplicity, brackets â€œ\(\{\)â€ and â€œ\(\}\)â€ are usually omitted in transactions and rules.  
å…¶ä¸­ \(\{ \text{ç‰›è‚‰, é¸¡è‚‰} \}\) æ˜¯ \( X \)ï¼Œ\(\{ \text{å¥¶é…ª} \}\) æ˜¯ \( Y \)ã€‚ä¸ºç®€åŒ–èµ·è§ï¼Œäº‹åŠ¡å’Œè§„åˆ™ä¸­çš„èŠ±æ‹¬å·â€œ\(\{\)â€å’Œâ€œ\(\}\)â€é€šå¸¸è¢«çœç•¥ã€‚  

===== Page 7 =====  
# Some other definitions  
# å…¶ä»–å®šä¹‰  

- The transaction \( t_i \in T \) contains the itemset \( X \subseteq I \) iff \( X \subseteq t_i \)  
- äº‹åŠ¡ \( t_i \in T \) åŒ…å«é¡¹é›† \( X \subseteq I \) å½“ä¸”ä»…å½“ \( X \subseteq t_i \)  

- In that case, we also say that \( X \) covers \( t_i \)  
- åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬ä¹Ÿè¯´ \( X \) è¦†ç›–äº† \( t_i \)  

- The support count of \( X \) in \( T \) is the number of transactions in \( T \) that contain \( X \). The support count is denoted by \( X.count \)  
- \( X \) åœ¨ \( T \) ä¸­çš„æ”¯æŒè®¡æ•°æ˜¯ \( T \) ä¸­åŒ…å« \( X \) çš„äº‹åŠ¡æ•°é‡ã€‚æ”¯æŒè®¡æ•°è®°ä¸º \( X.count \)  

===== Page 8 =====  
Support and Confidence of a rule  
è§„åˆ™çš„æ”¯æŒåº¦å’Œç½®ä¿¡åº¦  

â€¢ Given an association rule ğ‘‹â†’ğ‘Œ, we define its support and confidence:  
â€¢ ç»™å®šå…³è”è§„åˆ™ ğ‘‹â†’ğ‘Œï¼Œæˆ‘ä»¬å®šä¹‰å…¶æ”¯æŒåº¦å’Œç½®ä¿¡åº¦ï¼š  

===== Page 9 =====  
# Relationships with probabilities  
# ä¸æ¦‚ç‡çš„å…³ç³»  

- Support is the percentage of transactions in \( T \) that contains \( X \cup Y \), i.e., that contains both \( X \) and \( Y \).  
- æ”¯æŒåº¦æ˜¯ \( T \) ä¸­åŒ…å« \( X \cup Y \)ï¼ˆå³åŒæ—¶åŒ…å« \( X \) å’Œ \( Y \)ï¼‰çš„äº‹åŠ¡çš„ç™¾åˆ†æ¯”ã€‚  

- Support is an estimate of \( P(X \cup Y) \) or, better, it estimates \( P(X \text{ and } Y) = P(X, Y) \)  
- æ”¯æŒåº¦æ˜¯å¯¹ \( P(X \cup Y) \) çš„ä¼°è®¡ï¼Œæ›´å‡†ç¡®åœ°è¯´ï¼Œå®ƒä¼°è®¡ \( P(X \text{ å’Œ } Y) = P(X, Y) \)ã€‚  

- Confidence is the percentage of transactions in \( T \) containing \( X \) that also contain \( Y \)  
- ç½®ä¿¡åº¦æ˜¯ \( T \) ä¸­åŒ…å« \( X \) çš„äº‹åŠ¡ä¸­åŒæ—¶åŒ…å« \( Y \) çš„ç™¾åˆ†æ¯”ã€‚  

- Confidence is an estimate of \( P(Y|X) \)  
- ç½®ä¿¡åº¦æ˜¯å¯¹ \( P(Y|X) \) çš„ä¼°è®¡ã€‚  

- RECALL conditional probability definition:  
- å›é¡¾æ¡ä»¶æ¦‚ç‡çš„å®šä¹‰ï¼š  

\[P(Y|X) = \frac{P(X,Y)}{P(X)} \Rightarrow P(X,Y) = P(Y|X)P(X) = P(X|Y)P(Y)\]  
\[P(Y|X) = \frac{P(X,Y)}{P(X)} \Rightarrow P(X,Y) = P(Y|X)P(X) = P(X|Y)P(Y)\]  

===== Page 10 =====  
# Why Support and Confidence?  
# ä¸ºä»€ä¹ˆéœ€è¦æ”¯æŒåº¦å’Œç½®ä¿¡åº¦ï¼Ÿ  

- Support is a useful measure because if it is too low, the rule may just occur due to chance. Furthermore, in a business environment, a rule covering too few cases (or transactions) may not be useful because it does not make business sense to act on such a rule (not profitable).  
- æ”¯æŒåº¦æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„åº¦é‡ï¼Œå› ä¸ºå¦‚æœæ”¯æŒåº¦è¿‡ä½ï¼Œè§„åˆ™å¯èƒ½åªæ˜¯å¶ç„¶å‡ºç°ã€‚æ­¤å¤–ï¼Œåœ¨å•†ä¸šç¯å¢ƒä¸­ï¼Œè¦†ç›–å¤ªå°‘æ¡ˆä¾‹ï¼ˆæˆ–äº‹åŠ¡ï¼‰çš„è§„åˆ™å¯èƒ½æ²¡æœ‰ç”¨ï¼Œå› ä¸ºåŸºäºè¿™ç§è§„åˆ™é‡‡å–è¡ŒåŠ¨æ²¡æœ‰å•†ä¸šæ„ä¹‰ï¼ˆä¸ç›ˆåˆ©ï¼‰ã€‚  

- Confidence determines the predictability of the rule. If the confidence of a rule is too low, one cannot reliably infer or predict Y from X. A rule with low predictability is of limited use.  
- ç½®ä¿¡åº¦å†³å®šäº†è§„åˆ™çš„å¯é¢„æµ‹æ€§ã€‚å¦‚æœè§„åˆ™çš„ç½®ä¿¡åº¦è¿‡ä½ï¼Œå°±æ— æ³•å¯é åœ°ä»Xæ¨æ–­æˆ–é¢„æµ‹Yã€‚å¯é¢„æµ‹æ€§ä½çš„è§„åˆ™ç”¨é€”æœ‰é™ã€‚  

===== Page 11 =====  
# Mining of Association Rules  
# å…³è”è§„åˆ™çš„æŒ–æ˜  

Given a transaction set \( T \), the problem of mining association rules is to discover all association rules in \( T \) that have support and confidence greater than or equal to the user-specified minimum support (denoted by **minsup**) and minimum confidence (denoted by **minconf**).  
ç»™å®šäº‹åŠ¡é›† \( T \)ï¼ŒæŒ–æ˜å…³è”è§„åˆ™çš„é—®é¢˜æ˜¯å‘ç° \( T \) ä¸­æ‰€æœ‰æ”¯æŒåº¦å’Œç½®ä¿¡åº¦å¤§äºæˆ–ç­‰äºç”¨æˆ·æŒ‡å®šçš„æœ€å°æ”¯æŒåº¦ï¼ˆè®°ä¸º **minsup**ï¼‰å’Œæœ€å°ç½®ä¿¡åº¦ï¼ˆè®°ä¸º **minconf**ï¼‰çš„å…³è”è§„åˆ™ã€‚  

===== Page 12 =====  
# Example  
# ç¤ºä¾‹  

**Input**  
**è¾“å…¥**  

tâ‚:  
Beef, Chicken, Milk  
ç‰›è‚‰, é¸¡è‚‰, ç‰›å¥¶  

tâ‚‚:  
Beef, Cheese  
ç‰›è‚‰, å¥¶é…ª  

tâ‚ƒ:  
Cheese, Boots  
å¥¶é…ª, é´å­  

tâ‚„:  
Beef, Chicken, Cheese  
ç‰›è‚‰, é¸¡è‚‰, å¥¶é…ª  

tâ‚…:  
Beef, Chicken, Clothes, Cheese, Milk  
ç‰›è‚‰, é¸¡è‚‰, è¡£æœ, å¥¶é…ª, ç‰›å¥¶  

tâ‚†:  
Chicken, Clothes, Milk  
é¸¡è‚‰, è¡£æœ, ç‰›å¥¶  

tâ‚‡:  
Chicken, Milk, Clothes  
é¸¡è‚‰, ç‰›å¥¶, è¡£æœ  

**minsup = 30%**  
**æœ€å°æ”¯æŒåº¦ = 30%**  

**minconf = 80%**  
**æœ€å°ç½®ä¿¡åº¦ = 80%**  

The following association rules are valid:  
ä»¥ä¸‹å…³è”è§„åˆ™æ˜¯æœ‰æ•ˆçš„ï¼š  

**Expected Output**  
**é¢„æœŸè¾“å‡º**  

Rule 1:  
Chicken, Clothes â†’ Milk  
é¸¡è‚‰, è¡£æœ â†’ ç‰›å¥¶  

Rule 2:  
Clothes, Milk â†’ Chicken  
è¡£æœ, ç‰›å¥¶ â†’ é¸¡è‚‰  

Rule 3:  
Clothes â†’ Milk, Chicken  
è¡£æœ â†’ ç‰›å¥¶, é¸¡è‚‰  

[sup = 3/7, conf = 3/3]  
[æ”¯æŒåº¦ = 3/7, ç½®ä¿¡åº¦ = 3/3]  

[sup = 3/7, conf = 3/3]  
[æ”¯æŒåº¦ = 3/7, ç½®ä¿¡åº¦ = 3/3]  

[sup = 3/7, conf = 3/3]  
[æ”¯æŒåº¦ = 3/7, ç½®ä¿¡åº¦ = 3/3]  

===== Page 13 =====  
# Apriori Algorithm  
# Aprioriç®—æ³•  

- Apriori is one of the best known algorithm for mining association rules  
- Aprioriæ˜¯æŒ–æ˜å…³è”è§„åˆ™æœ€è‘—åçš„ç®—æ³•ä¹‹ä¸€  

- The Apriori algorithm has been proposed in *Agrawal, Rakesh, and Ramakrishnan Srikant. "Fast algorithms for mining association rules." Proc. 20th int. conf. very large data bases, VLDB. Vol. 1215. 1994.*  
- Aprioriç®—æ³•ç”±*Agrawal, Rakeshå’ŒRamakrishnan Srikant*åœ¨è®ºæ–‡ã€ŠFast algorithms for mining association rulesã€‹ä¸­æå‡ºï¼Œå‘è¡¨äº1994å¹´VLDBä¼šè®®ã€‚  

===== Page 14 =====  
# Apriori algorithm: how it works  
# Aprioriç®—æ³•çš„å·¥ä½œåŸç†  

- Apriori works in two steps:  
- Aprioriç®—æ³•åˆ†ä¸ºä¸¤æ­¥ï¼š  

1. **Generate all frequent itemsets:** A frequent itemset is an itemset that has transaction support above minsup  
1. **ç”Ÿæˆæ‰€æœ‰é¢‘ç¹é¡¹é›†ï¼š** é¢‘ç¹é¡¹é›†æ˜¯æ”¯æŒåº¦é«˜äºæœ€å°æ”¯æŒåº¦çš„é¡¹é›†  

2. **Generate all confident association rules from the frequent itemsets:**  
   A confident association rule is a rule with confidence above minconf  
2. **ä»é¢‘ç¹é¡¹é›†ä¸­ç”Ÿæˆæ‰€æœ‰ç½®ä¿¡å…³è”è§„åˆ™ï¼š**  
   ç½®ä¿¡å…³è”è§„åˆ™æ˜¯ç½®ä¿¡åº¦é«˜äºæœ€å°ç½®ä¿¡åº¦çš„è§„åˆ™  

- Note: in practical applications, sometimes only the first step is enough to reach the objective at hand  
- æ³¨æ„ï¼šåœ¨å®é™…åº”ç”¨ä¸­ï¼Œæœ‰æ—¶ä»…ç¬¬ä¸€æ­¥å°±è¶³ä»¥å®ç°ç›®æ ‡  

===== Page 15 =====  
# Apriori step 1: generate all frequent itemsets  
# Aprioriç¬¬ä¸€æ­¥ï¼šç”Ÿæˆæ‰€æœ‰é¢‘ç¹é¡¹é›†  

## Downward Closure Property: If an itemset has minimum support, then every non-empty subset of this itemset also has minimum support.  
## å‘ä¸‹é—­åŒ…æ€§è´¨ï¼šå¦‚æœä¸€ä¸ªé¡¹é›†å…·æœ‰æœ€å°æ”¯æŒåº¦ï¼Œé‚£ä¹ˆå®ƒçš„æ¯ä¸ªéç©ºå­é›†ä¹Ÿå…·æœ‰æœ€å°æ”¯æŒåº¦ã€‚  

---  

### Algorithm Apriori(T)  
### Aprioriç®—æ³•(T)  

1. \( C_1 \leftarrow \text{init-pass}(T); \)  
   // the first pass over \( T \)  
   // ç¬¬ä¸€æ¬¡æ‰«æ \( T \)  

2. \( F_i \leftarrow \{ f | f \in C_k, f \text{count}/n \geq \text{minsup} \}; \)  
   // \( n \) is the no. of transactions in \( T \)  
   // \( n \) æ˜¯ \( T \) ä¸­çš„äº‹åŠ¡æ•°é‡  

3. **for** \((k = 2; F_{i-1} \neq \emptyset; k++)\) **do**  
   // subsequent passes over \( T \)  
   // åç»­æ‰«æ \( T \)  

4. \( C_k \leftarrow \text{candidate-gen}(F_{i-1}); \)  

5. **for** each transaction \( t \in T \) **do**  
   // scan the data once  
   // æ‰«ææ•°æ®ä¸€æ¬¡  

6. **for** each candidate \( c \in C_k \) **do**  

7. **if** \( c \) is contained in \( t \) **then**  

8. \( c.\text{count}+t; \)  

9. **endfor**  

10. \( F_k \leftarrow \{ c \in C_k | c.\text{count}/n \geq \text{minsup} \} \)  

11. **endfor**  

12. **return** \( F \leftarrow \bigcup_k F_k; \)  

---  

### Function candidate-gen(\( F_{i-1} \))  
### å€™é€‰ç”Ÿæˆå‡½æ•°(\( F_{i-1} \))  

1. \( C_k \leftarrow \emptyset; \)  
   // initialize the set of candidates  
   // åˆå§‹åŒ–å€™é€‰é›†  

2. **forall** \( f_1, f_2 \in F_{i-1} \)  
   // find all pairs of frequent itemsets  
   // æ‰¾åˆ°æ‰€æœ‰é¢‘ç¹é¡¹é›†å¯¹  

3. with \( f_1 = \{ i_1, \ldots, i_{k-2}, i_{k-1} \} \)  
   // that differ only in the last item  
   // ä»…åœ¨æœ€åä¸€é¡¹ä¸åŒ  

4. and \( f_2 = \{ i_1, \ldots, i_{k-3}, i_{k-1} \} \)  

5. and \( i_{k-1} < i_{k-1} \) **do**  
    // according to the lexicographic order  
    // æ ¹æ®å­—å…¸åº  

6. \( c \leftarrow \{ i_1, \ldots, i_{k-1}, i_{k-1} \}; \)  
    // join the two itemsets \( f_1 \) and \( f_2 \)  
    // è¿æ¥ä¸¤ä¸ªé¡¹é›† \( f_1 \) å’Œ \( f_2 \)  

7. \( C_k \leftarrow C_k \cup \{ c \}; \)  
    // add the new itemset \( c \) to the candidates  
    // å°†æ–°é¡¹é›† \( c \) åŠ å…¥å€™é€‰é›†  

8. **for** each \((k-1)\)-subset \( s \) of \( c \) **do**  

9. **if** \((s \notin F_{i-1})\) **then**  

10. delete \( c \) from \( C_k; \)  

11. **endfor**  

12. **endfor**  

13. **return** \( C_k; \)  
    // delete \( c \) from the candidates  
    // ä»å€™é€‰é›†ä¸­åˆ é™¤ \( c \)  
    // return the generated candidates  
    // è¿”å›ç”Ÿæˆçš„å€™é€‰é›†  

---  

Note: Not necessary to load the whole data into memory before processing, only one transaction must reside in memory.  
æ³¨æ„ï¼šå¤„ç†å‰æ— éœ€å°†æ‰€æœ‰æ•°æ®åŠ è½½åˆ°å†…å­˜ä¸­ï¼Œåªéœ€ä¸€ä¸ªäº‹åŠ¡é©»ç•™åœ¨å†…å­˜ä¸­å³å¯ã€‚  

===== Page 16 =====  
# Apriori step 1 ... an "animated" example  
# Aprioriç¬¬ä¸€æ­¥...ä¸€ä¸ªâ€œåŠ¨æ€â€ç¤ºä¾‹  

- We have the following dataset of transactions  
- æˆ‘ä»¬æœ‰ä»¥ä¸‹äº‹åŠ¡æ•°æ®é›†  

| TID    | Items |  
|---|---|  
| T1    | 1 3 4   |  
| T2    | 2 3 5   |  
| T3    | 1 2 3 5 |  
| T4    | 2 5    |  
| T5    | 1 3 5   |  

and we assume minsup=40%, i.e., at least 2 transactions need to be covered, so in the following I simplify support to be the number of transactions covered by a given itemset  
å‡è®¾æœ€å°æ”¯æŒåº¦ä¸º40%ï¼Œå³è‡³å°‘éœ€è¦è¦†ç›–2ä¸ªäº‹åŠ¡ï¼Œå› æ­¤åœ¨ä»¥ä¸‹å†…å®¹ä¸­ï¼Œæˆ‘å°†æ”¯æŒåº¦ç®€åŒ–ä¸ºç»™å®šé¡¹é›†è¦†ç›–çš„äº‹åŠ¡æ•°é‡  

===== Page 17 =====  
Apriori step 1 â€¦ an "animated" example  
Aprioriç¬¬ä¸€æ­¥...ä¸€ä¸ªâ€œåŠ¨æ€â€ç¤ºä¾‹  

â€¢ Find candidate itemsets of length 1  
â€¢ ç”Ÿæˆé•¿åº¦ä¸º1çš„å€™é€‰é¡¹é›†  

===== Page 18 =====  
# Apriori step 1 ... an "animated" example  
# Aprioriç¬¬ä¸€æ­¥...ä¸€ä¸ªâ€œåŠ¨æ€â€ç¤ºä¾‹  

- Filter-out candidates with support<minsup and obtain F1 (frequent itemsets of length 1)  
- è¿‡æ»¤æ‰æ”¯æŒåº¦å°äºæœ€å°æ”¯æŒåº¦çš„å€™é€‰ï¼Œå¾—åˆ°F1ï¼ˆé•¿åº¦ä¸º1çš„é¢‘ç¹é¡¹é›†ï¼‰  

| Itemset | Support |  
|---|---|  
| (1)    | 3    |  
| (2)    | 3    |  
| (3)    | 4    |  
| (4)    | 1    |  
| (5)    | 4    |  

| Itemset | Support |  
|---|---|  
| (1)    | 3    |  
| (2)    | 3    |  
| (3)    | 4    |  
| (5)    | 4    |  

===== Page 19 =====  
Apriori step 1 â€¦ an "animated" example  
Aprioriç¬¬ä¸€æ­¥...ä¸€ä¸ªâ€œåŠ¨æ€â€ç¤ºä¾‹  

â€¢ Create candidate of length 2 and filter-out low-support itemsets  
â€¢ ç”Ÿæˆé•¿åº¦ä¸º2çš„å€™é€‰å¹¶è¿‡æ»¤æ‰ä½æ”¯æŒåº¦çš„é¡¹é›†  

===== Page 20 =====  
# Apriori step 1 ... an "animated" example  
# Aprioriç¬¬ä¸€æ­¥...ä¸€ä¸ªâ€œåŠ¨æ€â€ç¤ºä¾‹  

- Create candidates of length 3  
- ç”Ÿæˆé•¿åº¦ä¸º3çš„å€™é€‰  

| TID    | Items    |  
|---|---|  
| T1    | 1 3 4   |  
| T2    | 2 3 5   |  
| T3    | 1 2 3 5   |  
| T4    | 2 5    |  
| T5    | 1 3 5   |  

| Itemset    | In F27 |  
|---|---|  
| {1,2,3}, {1,2}, {1,3}, {2,3} | NO    |  
| {1,2,5}, {1,2}, {1,5}, {2,5} | NO    |  
| {1,3,5},{1,5}, {1,3}, {3,5} | YES    |  
| {2,3,5}, {2,3}, {2,5}, {3,5} | YES    |  

===== Page 21 =====  
# Apriori step 1 ... an "animated" example  
# Aprioriç¬¬ä¸€æ­¥...ä¸€ä¸ªâ€œåŠ¨æ€â€ç¤ºä¾‹  

- Filter-out C3 to generate frequent itemsets of length 3  
- è¿‡æ»¤æ‰C3ç”Ÿæˆé•¿åº¦ä¸º3çš„é¢‘ç¹é¡¹é›†  

| TID    | Items    |  
|---|---|  
| T1    | 1 3 4    |  
| T2    | 2 3 5    |  
| T3    | 1 2 3 5    |  
| T4    | 2 5    |  
| T5    | 1 3 5    |  

| Itemset   | Support    |  
|---|---|  
| {1,3,5}    | 2    |  
| {2,3,5}    | 2    |  

===== Page 22 =====  
# Apriori step 1 ... an "animated" example  
# Aprioriç¬¬ä¸€æ­¥...ä¸€ä¸ªâ€œåŠ¨æ€â€ç¤ºä¾‹  

- Create candidates of length 4  
- ç”Ÿæˆé•¿åº¦ä¸º4çš„å€™é€‰  

| TID | Items |  
|---|---|  
| T1   | 1 3 4    |  
| T2   | 2 3 5    |  
| T3   | 1 2 3 5    |  
| T4   | 2 5    |  
| T5   | 1 3 5    |  

| Itemset | Support |  
|---|---|  
| {1,3,5} | 2    |  
| {2,3,5} | 2    |  

| Itemset | Support |  
|---|---|  
| {1,2,3,5} | 1    |  

Since all candidates in C4 are filtered-out, the algorithm terminates and its result is the union of F1, F2, and F3.  
ç”±äºC4ä¸­çš„æ‰€æœ‰å€™é€‰éƒ½è¢«è¿‡æ»¤æ‰ï¼Œç®—æ³•ç»ˆæ­¢ï¼Œå…¶ç»“æœæ˜¯F1ã€F2å’ŒF3çš„å¹¶é›†ã€‚  

===== Page 23 =====  
# Apriori step 2: generate association rules  
# Aprioriç¬¬äºŒæ­¥ï¼šç”Ÿæˆå…³è”è§„åˆ™  

- Simple strategy:  
   for every frequent itemset \( f \) and for each subset \( \alpha \subset f \):  
   output the rule  
   \[   (f - \alpha) \to \alpha, \text{ if }\]  
   \[   confidence = \frac{f.count}{(f - \alpha).count} \geq minconf,\]  
   where \( f.count \) (or \((f - \alpha).count\)) is the support count of \( f \) (or \((f - \alpha)\)), which can be easily obtained from the supports computed in step 1.  
- ç®€å•ç­–ç•¥ï¼š  
   å¯¹äºæ¯ä¸ªé¢‘ç¹é¡¹é›† \( f \) å’Œæ¯ä¸ªå­é›† \( \alpha \subset f \)ï¼š  
   è¾“å‡ºè§„åˆ™  
   \[   (f - \alpha) \to \alpha, \text{ å¦‚æœ }\]  
   \[   ç½®ä¿¡åº¦ = \frac{f.count}{(f - \alpha).count} \geq minconf,\]  
   å…¶ä¸­ \( f.count \)ï¼ˆæˆ– \((f - \alpha).count\)ï¼‰æ˜¯ \( f \)ï¼ˆæˆ– \((f - \alpha)\)ï¼‰çš„æ”¯æŒè®¡æ•°ï¼Œå¯ä»¥ä»ç¬¬ä¸€æ­¥è®¡ç®—çš„æ”¯æŒåº¦ä¸­è½»æ¾è·å¾—ã€‚  

===== Page 24 =====  
# Apriori step 2... a more efficient strategy  
# Aprioriç¬¬äºŒæ­¥...æ›´é«˜æ•ˆçš„ç­–ç•¥  

- In order to design an efficient strategy, let's observe that the support count of \( f \) does not change as \(\alpha\) changes  
- ä¸ºäº†è®¾è®¡ä¸€ä¸ªé«˜æ•ˆçš„ç­–ç•¥ï¼Œæˆ‘ä»¬æ³¨æ„åˆ° \( f \) çš„æ”¯æŒè®¡æ•°ä¸ä¼šéšç€ \(\alpha\) çš„å˜åŒ–è€Œå˜åŒ–  

- Therefore, if \((f - \alpha) \to \alpha\) is valid, then all the rules of the form \((f - \alpha_{sub}) \to \alpha_{sub}\), with \(\alpha_{sub} \subset \alpha\), are valid  
- å› æ­¤ï¼Œå¦‚æœ \((f - \alpha) \to \alpha\) æ˜¯æœ‰æ•ˆçš„ï¼Œé‚£ä¹ˆæ‰€æœ‰å½¢å¼ä¸º \((f - \alpha_{sub}) \to \alpha_{sub}\)ï¼ˆå…¶ä¸­ \(\alpha_{sub} \subset \alpha\)ï¼‰çš„è§„åˆ™ä¹Ÿæ˜¯æœ‰æ•ˆçš„  

- Example: if \(A, B \to C, D\) is valid, then also \(A, B, C \to D\) and \(A, B, D \to C\) are valid  
- ä¾‹å¦‚ï¼šå¦‚æœ \(A, B \to C, D\) æ˜¯æœ‰æ•ˆçš„ï¼Œé‚£ä¹ˆ \(A, B, C \to D\) å’Œ \(A, B, D \to C\) ä¹Ÿæ˜¯æœ‰æ•ˆçš„  

- Therefore, an efficient algorithm very similar to "candidate-gen" (seen some slides before) can be devised  
- å› æ­¤ï¼Œå¯ä»¥è®¾è®¡ä¸€ä¸ªä¸â€œå€™é€‰ç”Ÿæˆâ€ï¼ˆå‰é¢å¹»ç¯ç‰‡ä¸­æåˆ°çš„ï¼‰éå¸¸ç›¸ä¼¼çš„é«˜æ•ˆç®—æ³•  

===== Page 25 =====  
# Lift: another measure for association rules  
# æå‡åº¦ï¼šå…³è”è§„åˆ™çš„å¦ä¸€ç§åº¦é‡  

- \( \text{Lift}(X \to Y) = \frac{\text{Confidence}(X \to Y)}{Y.\text{count}/n} \)  
- \( \text{æå‡åº¦}(X \to Y) = \frac{\text{ç½®ä¿¡åº¦}(X \to Y)}{Y.\text{count}/n} \)  

- **Lift** is an estimate of  
  \[  \frac{P(X,Y)}{P(Y)P(X)} \]  
- **æå‡åº¦** æ˜¯å¯¹ä»¥ä¸‹å€¼çš„ä¼°è®¡  
  \[  \frac{P(X,Y)}{P(Y)P(X)} \]  

- **Therefore** *lift* is a kind of "correlation" between \( X \) and \( Y \)  
- **å› æ­¤** *æå‡åº¦* æ˜¯ \( X \) å’Œ \( Y \) ä¹‹é—´çš„ä¸€ç§â€œç›¸å…³æ€§â€  

- Informally speaking, a high *lift* indicates that the importance of an association rule is not just a coincidence  
- é€šä¿—åœ°è¯´ï¼Œé«˜*æå‡åº¦*è¡¨æ˜å…³è”è§„åˆ™çš„é‡è¦æ€§ä¸ä»…ä»…æ˜¯å·§åˆ  

===== Page 26 =====  
One more example  
å¦ä¸€ä¸ªç¤ºä¾‹  

minsup = 0.5  
æœ€å°æ”¯æŒåº¦ = 0.5  

minconf = 0.8  
æœ€å°ç½®ä¿¡åº¦ = 0.8  

maxlen = 2  
æœ€å¤§é•¿åº¦ = 2  

INPUT  
è¾“å…¥  

===== Page 27 =====  
One more example  
å¦ä¸€ä¸ªç¤ºä¾‹  

minsup = 0.5  
æœ€å°æ”¯æŒåº¦ = 0.5  

minconf = 0.8  
æœ€å°ç½®ä¿¡åº¦ = 0.8  

maxlen = 2  
æœ€å¤§é•¿åº¦ = 2  

INPUT  
è¾“å…¥  

Support(A) = 3/5 = 0.6  
æ”¯æŒåº¦(A) = 3/5 = 0.6  

Support(B) = 3/5 = 0.6  
æ”¯æŒåº¦(B) = 3/5 = 0.6  

Support(C) = 2/5 = 0.4  
æ”¯æŒåº¦(C) = 2/5 = 0.4  

Support(D) = 4/5 = 0.8  
æ”¯æŒåº¦(D) = 4/5 = 0.8  

Support(E) = 3/5 = 0.6  
æ”¯æŒåº¦(E) = 3/5 = 0.6  

Support(A,B) = 2/5 = 0.4  
æ”¯æŒåº¦(A,B) = 2/5 = 0.4  

Support(A,D) = 2/5 = 0.4  
æ”¯æŒåº¦(A,D) = 2/5 = 0.4  

Support(A,E) = 1/5 = 0.2  
æ”¯æŒåº¦(A,E) = 1/5 = 0.2  

Support(B,D) = 2/5 = 0.4  
æ”¯æŒåº¦(B,D) = 2/5 = 0.4  

Support(B,E) = 1/5 = 0.2  
æ”¯æŒåº¦(B,E) = 1/5 = 0.2  

Support(D,E) = 3/5 = 0.6  
æ”¯æŒåº¦(D,E) = 3/5 = 0.6  

Support Computation  
æ”¯æŒåº¦è®¡ç®—  

===== Page 28 =====  
One more example  
å¦ä¸€ä¸ªç¤ºä¾‹  

minsup = 0.5  
æœ€å°æ”¯æŒåº¦ = 0.5  

minconf = 0.8  
æœ€å°ç½®ä¿¡åº¦ = 0.8  

maxlen = 2  
æœ€å¤§é•¿åº¦ = 2  

INPUT  
è¾“å…¥  

Support(A) = 3/5 = 0.6  
æ”¯æŒåº¦(A) = 3/5 = 0.6  

Support(B) = 3/5 = 0.6  
æ”¯æŒåº¦(B) = 3/5 = 0.6  

Support(C) = 2/5 = 0.4  
æ”¯æŒåº¦(C) = 2/5 = 0.4  

Support(D) = 4/5 = 0.8  
æ”¯æŒåº¦(D) = 4/5 = 0.8  

Support(E) = 3/5 = 0.6  
æ”¯æŒåº¦(E) = 3/5 = 0.6  

Support(A,B) = 2/5 = 0.4  
æ”¯æŒåº¦(A,B) = 2/5 = 0.4  

Support(A,D) = 2/5 = 0.4  
æ”¯æŒåº¦(A,D) = 2/5 = 0.4  

Support(A,E) = 1/5 = 0.2  
æ”¯æŒåº¦(A,E) = 1/5 = 0.2  

Support(B,D) = 2/5 = 0.4  
æ”¯æŒåº¦(B,D) = 2/5 = 0.4  

Support(B,E) = 1/5 = 0.2  
æ”¯æŒåº¦(B,E) = 1/5 = 0.2  

Support(D,E) = 3/5 = 0.6  
æ”¯æŒåº¦(D,E) = 3/5 = 0.6  

Support Computation  
æ”¯æŒåº¦è®¡ç®—  

Confidence(D->E) = 0.6 / 0.8 = 0.75  
ç½®ä¿¡åº¦(D->E) = 0.6 / 0.8 = 0.75  

Confidence(E->D) = 0.6 / 0.6 = 1  
ç½®ä¿¡åº¦(E->D) = 0.6 / 0.6 = 1  

Confidence Computation  
ç½®ä¿¡åº¦è®¡ç®—  

===== Page 29 =====  
One more example  
å¦ä¸€ä¸ªç¤ºä¾‹  

minsup = 0.5  
æœ€å°æ”¯æŒåº¦ = 0.5  

minconf = 0.8  
æœ€å°ç½®ä¿¡åº¦ = 0.8  

maxlen = 2  
æœ€å¤§é•¿åº¦ = 2  

INPUT  
è¾“å…¥  

Support(A) = 3/5 = 0.6  
æ”¯æŒåº¦(A) = 3/5 = 0.6  

Support(B) = 3/5 = 0.6  
æ”¯æŒåº¦(B) = 3/5 = 0.6  

Support(C) = 2/5 = 0.4  
æ”¯æŒåº¦(C) = 2/5 = 0.4  

Support(D) = 4/5 = 0.8  
æ”¯æŒåº¦(D) = 4/5 = 0.8  

Support(E) = 3/5 = 0.6  
æ”¯æŒåº¦(E) = 3/5 = 0.6  

Support(A,B) = 2/5 = 0.4  
æ”¯æŒåº¦(A,B) = 2/5 = 0.4  

Support(A,D) = 2/5 = 0.4  
æ”¯æŒåº¦(A,D) = 2/5 = 0.4  

Support(A,E) = 1/5 = 0.2  
æ”¯æŒåº¦(A,E) = 1/5 = 0.2  

Support(B,D) = 2/5 = 0.4  
æ”¯æŒåº¦(B,D) = 2/5 = 0.4  

Support(B,E) = 1/5 = 0.2  
æ”¯æŒåº¦(B,E) = 1/5 = 0.2  

Support(D,E) = 3/5 = 0.6  
æ”¯æŒåº¦(D,E) = 3/5 = 0.6  

Support Computation  
æ”¯æŒåº¦è®¡ç®—  

Confidence(D->E) = 0.6 / 0.8 = 0.75  
ç½®ä¿¡åº¦(D->E) = 0.6 / 0.8 = 0.75  

Confidence(E->D) = 0.6 / 0.6 = 1  
ç½®ä¿¡åº¦(E->D) = 0.6 / 0.6 = 1  

Confidence Computation  
ç½®ä¿¡åº¦è®¡ç®—  

Lift(E->D) = 1 / 0.8 = 1.25  
æå‡åº¦(E->D) = 1 / 0.8 = 1.25  

Lift Computation  
æå‡åº¦è®¡ç®—  

===== Page 30 =====  
# Practical applications other than market basket  
# è´­ç‰©ç¯®ä»¥å¤–çš„å®é™…åº”ç”¨  

- Any text documents can be seen as a transaction, where each distinct word/lemma is an item (duplicate words are removed)  
- ä»»ä½•æ–‡æœ¬æ–‡æ¡£éƒ½å¯ä»¥è¢«è§†ä¸ºäº‹åŠ¡ï¼Œå…¶ä¸­æ¯ä¸ªä¸åŒçš„å•è¯/è¯å…ƒæ˜¯ä¸€ä¸ªé¡¹ï¼ˆé‡å¤çš„å•è¯è¢«ç§»é™¤ï¼‰  

- Same as before, but consider windows of words of a given maximum length  
- ä¸ä¹‹å‰ç›¸åŒï¼Œä½†è€ƒè™‘ç»™å®šæœ€å¤§é•¿åº¦çš„å•è¯çª—å£  

- Relational tables with categorical values are easily seen as transactions  
- å…·æœ‰åˆ†ç±»å€¼çš„å…³ç³»è¡¨å¾ˆå®¹æ˜“è¢«è§†ä¸ºäº‹åŠ¡  

- If numerical values are present, we need to discretize them to categories  
  - Example:  
    \[    \begin{align*}  
    Temperature & \leq 0^\circ \\  
    0^\circ & < Temperature \leq 15^\circ \\  
    15^\circ & < Temperature \leq 25^\circ \\  
    \end{align*}\]  
    \[    \begin{align*}  
    => "very cold" \\  
    => "cold" \\  
    => "warm" \\  
    => "hot"  
    \end{align*}\]  
- å¦‚æœå­˜åœ¨æ•°å€¼ï¼Œæˆ‘ä»¬éœ€è¦å°†å…¶ç¦»æ•£åŒ–ä¸ºç±»åˆ«  
  - ä¾‹å¦‚ï¼š  
    \[    \begin{align*}  
    æ¸©åº¦ & \leq 0^\circ \\  
    0^\circ & < æ¸©åº¦ \leq 15^\circ \\  
    15^\circ & < æ¸©åº¦ \leq 25^\circ \\  
    \end{align*}\]  
    \[    \begin{align*}  
    => "éå¸¸å†·" \\  
    => "å†·" \\  
    => "æ¸©æš–" \\  
    => "çƒ­"  
    \end{align*}\]  

===== Page 31 =====  
# Some more (complex) extensions  
# æ›´å¤šï¼ˆå¤æ‚ï¼‰æ‰©å±•  

- Rare items problem: distinctive items may be interesting at different minimum supports.  
- ç¨€æœ‰é¡¹é—®é¢˜ï¼šç‹¬ç‰¹é¡¹å¯èƒ½åœ¨ä¸åŒçš„æœ€å°æ”¯æŒåº¦ä¸‹å…·æœ‰æ„ä¹‰ã€‚  

- Class labels: transactions may be labeled by classes and users may be interested in targeted rules, i.e., rules whose right-hand-side is a class label.  
- ç±»åˆ«æ ‡ç­¾ï¼šäº‹åŠ¡å¯èƒ½è¢«ç±»åˆ«æ ‡è®°ï¼Œç”¨æˆ·å¯èƒ½å¯¹ç›®æ ‡è§„åˆ™æ„Ÿå…´è¶£ï¼Œå³å³ä¾§æ˜¯ç±»åˆ«æ ‡ç­¾çš„è§„åˆ™ã€‚  

- Sequential patterns: association rules do not consider the order of transactions, so sequences of items (and not simply itemsets) can be considered.  
- åºåˆ—æ¨¡å¼ï¼šå…³è”è§„åˆ™ä¸è€ƒè™‘äº‹åŠ¡çš„é¡ºåºï¼Œå› æ­¤å¯ä»¥è€ƒè™‘é¡¹çš„åºåˆ—ï¼ˆè€Œä¸ä»…ä»…æ˜¯é¡¹é›†ï¼‰ã€‚  

- All these cases have been formally defined and specific mining algorithms (which are extensions of the Apriori algorithm) have been proposed  
- æ‰€æœ‰è¿™äº›æƒ…å†µéƒ½å·²æ­£å¼å®šä¹‰ï¼Œå¹¶æå‡ºäº†ç‰¹å®šçš„æŒ–æ˜ç®—æ³•ï¼ˆè¿™äº›ç®—æ³•æ˜¯Aprioriç®—æ³•çš„æ‰©å±•ï¼‰ã€‚  

===== Page 32 =====  
Hands-on with Python  
Pythonå®è·µ  

â€¢ Requirements:  
â€¢ è¦æ±‚ï¼š  

â€¢ Python (>=3.8, but it may be ok also an older version)  
â€¢ Pythonï¼ˆ>=3.8ï¼Œä½†æ—§ç‰ˆæœ¬ä¹Ÿå¯ä»¥ï¼‰  

â€¢ pip install mlxtend  
â€¢ å®‰è£…mlxtendåº“  

â€¢ Two examples in arules.zip:  
â€¢ arules.zipä¸­çš„ä¸¤ä¸ªç¤ºä¾‹ï¼š  

â€¢ basket.py (mining of rules for a simple market basket)  
â€¢ basket.pyï¼ˆç®€å•è´­ç‰©ç¯®çš„è§„åˆ™æŒ–æ˜ï¼‰  

â€¢ recipes.py (mining of rules for a dataset of recipesâ€¦ where recipes are lists formed by cuisine_type + list of ingredients)  
â€¢ recipes.pyï¼ˆé£Ÿè°±æ•°æ®é›†çš„è§„åˆ™æŒ–æ˜â€¦å…¶ä¸­é£Ÿè°±æ˜¯ç”±èœç³»ç±»å‹å’Œé…æ–™åˆ—è¡¨ç»„æˆçš„åˆ—è¡¨ï¼‰  

===== Page 33 =====  
# References  
# å‚è€ƒæ–‡çŒ®  

- **Liu, Bing.** *Web data mining: exploring hyperlinks, contents, and usage data. Berlin: springer, 2011. Chapter 2.*  
- **åˆ˜å…µ.** *ã€Šç½‘ç»œæ•°æ®æŒ–æ˜ï¼šæ¢ç´¢è¶…é“¾æ¥ã€å†…å®¹å’Œç”¨æ³•æ•°æ®ã€‹. æŸæ—: Springer, 2011. ç¬¬2ç« .*  

- **Agrawal, Rakesh, and Ramakrishnan Srikant.** "Fast algorithms for mining association rules." Proc. 20th int. conf. very large data bases, VLDB. Vol. 1215. 1994.  
  https://courses.cs.duke.edu/compsci516/spring16/Papers/AssociationRuleMining.pdf  
- **Agrawal, Rakeshå’ŒRamakrishnan Srikant.** "Fast algorithms for mining association rules." ç¬¬20å±Šå›½é™…å¤§å‹æ•°æ®åº“
