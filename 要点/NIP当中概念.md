### **NLP Pipeline 每个概念详细通俗讲解**

---

#### **1. 分词（Tokenization）**
- **是什么**：把句子拆成最小单位（单词、标点、符号）。  
- **例子**：  
  `"I love NLP!"` → `["I", "love", "NLP", "!"]`  
- **为什么重要**：计算机无法直接理解句子，需要先拆成“零件”。
- **特殊处理**：  
  - `"U.S.A"` 保持为一个词（专有名词），而 `"don't"` 可拆为 `["do", "n't"]`。

---

#### **2. 分句（Sentence Segmentation）**
- **是什么**：把段落拆成独立句子。  
- **例子**：  
  `"你好。今天下雨了。"` → `["你好。", "今天下雨了。"]`  
- **难点**：  
  - 缩写如 `"Dr."` 中的点不能误认为句号。

---

#### **3. 词性标注（POS Tagging）**
- **是什么**：给每个词打标签（名词、动词等）。  
- **例子**：  
  `"猫/Noun 吃/Verb 鱼/Noun"`  
- **常见标签**：  
  - `NOUN`（名词）、`VERB`（动词）、`ADJ`（形容词）、`ADP`（介词如“在”）。

---

#### **4. 词形还原（Lemmatization）**
- **是什么**：把单词变回字典中的基础形式。  
- **例子**：  
  `"running" → "run"`，`"better" → "good"`  
- **对比词干提取（Stemming）**：  
  - 词干提取更粗暴：`"university" → "univers"`（可能无意义）。

---

#### **5. 命名实体识别（NER）**
- **是什么**：识别文本中的人名、地名、组织等。  
- **例子**：  
  `"马云在阿里巴巴工作"` → `"马云/人名 阿里巴巴/组织"`  
- **常见类型**：  
  - `PERSON`（人名）、`GPE`（国家/城市）、`ORG`（组织）。

---

#### **6. 依存句法分析（Dependency Parsing）**
- **是什么**：分析句子中词的语法关系（谁修饰谁）。  
- **例子**：  
  `"猫吃鱼"` → “猫”是主语，“吃”是动作，“鱼”是宾语。  
- **可视化**：树状图，根节点是核心动词。

---

#### **7. 词向量（Word Embedding）**
- **是什么**：用一串数字表示单词，语义相似的词数字接近。  
- **例子**：  
  - `"猫"` 的向量可能是 `[0.1, -0.3, 0.8, ...]`（300维）。  
  - `"猫"` 和 `"狗"` 的向量距离比 `"猫"` 和 `"电脑"` 更近。  
- **工具**：Spacy 的 `token.vector` 直接调用预训练向量。

---

#### **8. 句子向量（Sentence Embedding）**
- **是什么**：把整个句子变成向量，用于比较句子相似度。  
- **例子**：  
  - `"我喜欢猫"` 和 `"我养了一只猫"` 相似度较高（0.8）。  
  - `"今天天气好"` 和 `"编程很难"` 相似度低（0.1）。  
- **工具**：`SentenceTransformer` 库（如 `all-MiniLM-L6-v2` 模型）。

---

#### **9. 拼写检查（Spell Checking）**
- **是什么**：自动纠正拼写错误。  
- **原理**：计算编辑距离（如 `"beutiful"` → `"beautiful"` 需插入一个 `a`）。  
- **工具**：`pyspellchecker` 库。

---

#### **10. 大语言模型（LLM）**
- **是什么**：如 GPT、LLAMA，能理解并生成自然语言。  
- **应用**：  
  - **零样本分类**：直接让模型分类文本（无需训练）。  
    ```python
    输入："""分类文本情感：正面、负面、中性。文本：'这部电影很棒'"""
    输出：正面
    ```
  - **问答系统**：结合检索技术回答复杂问题。

---

### **关键工具总结**
| 任务               | 工具/库                  | 代码示例                          |
|--------------------|--------------------------|-----------------------------------|
| 分词、NER          | Spacy                    | `nlp("文本")` → `doc.ents`       |
| 句子向量           | SentenceTransformer      | `model.encode("句子")`           |
| 拼写检查           | pyspellchecker           | `spell.correction("wrng")`       |
| 词干提取           | NLTK 的 PorterStemmer    | `stemmer.stem("running")` → `"run"` |

---

### **一句话记忆口诀**
**“分分词，标词性，实体识别抓重点，向量一算知相似，大模型来当外挂！”**  
（对应：分词→词性→NER→词向量→LLM）
